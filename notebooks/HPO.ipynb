{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZtMkXr2vBqs"
   },
   "source": [
    "# Explore hyperparameter tuning with Ablator\n",
    "\n",
    "In this demo, we are gonna train a LeNet model with MNIST dataset with Ablator under Colab enviroments. After that, we will also use the Multi-processing feature of Ablator's to tune different hyperparameters for our model and compare the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_mMoS5mvsaI"
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we start, please enable GPU on your CoLab. Please select the `Change Runtime type` option from the CoLab toolbar and choose `GPU` as the hardware accelerator.\n",
    "\n",
    "To start with, we can clone the Ablator repository from Github to our CoLab workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OOUZdwtYvnp8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/iordanis/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import ablator\n",
    "except ImportError:\n",
    "    !pip install git+https://github.com/fostiropoulos/ablator.git@v0.0.1-misc-fixes\n",
    "    print(\"Stopping RUNTIME! Please run again.\")\n",
    "    import os\n",
    "\n",
    "    os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KqfnhrzSwXvn"
   },
   "source": [
    "Then we install all the dependecies.\n",
    "\n",
    "Please note that: Since there are some package version conflicts, the installation process is seperated. We will fix this problem later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YXAgFLsO0TIz"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Callable, Dict\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dMv5LTHs0lNE"
   },
   "outputs": [],
   "source": [
    "from ablator import (\n",
    "    ModelConfig,\n",
    "    ModelWrapper,\n",
    "    RunConfig,\n",
    "    configclass,\n",
    "    Literal,\n",
    "    ParallelConfig,\n",
    "    ParallelTrainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2fmpHLI3giz"
   },
   "source": [
    "## Set up basic configurations\n",
    "\n",
    "First thing for using Ablator is to set up the configurations, including the model configurations and the training configurations.\n",
    "\n",
    "Since we are running Ablator on CoLab, we define the inline parameters directly and use **NO** configuration files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5q-A4_El7W5e"
   },
   "outputs": [],
   "source": [
    "# Customized model config subclass, inheriting from ModelConfig base class\n",
    "@configclass\n",
    "class LenetConfig(ModelConfig):\n",
    "    # Configurable attributes\n",
    "    name: Literal[\"lenet5\"]\n",
    "\n",
    "\n",
    "# Customized Run config subclass, inheriting from RunConfig base class\n",
    "@configclass\n",
    "class LenetRunConfig(RunConfig):\n",
    "    model_config: LenetConfig\n",
    "\n",
    "\n",
    "# Customized Parallel Training config class, inheriting from ParallelConfig base class\n",
    "@configclass\n",
    "class MyParallelConfig(ParallelConfig):\n",
    "    model_config: LenetConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4-rKWTZFj2Y"
   },
   "source": [
    "Then we create objects for each necessary configuration classes and fill in the configuration values into them.\n",
    "\n",
    "In this demo, we implemented these configration objects:\n",
    "\n",
    "*   `TrainConfig`: Training parameters, including the dataset, epochs number, batch size and optimizer etc.\n",
    "*   `ModelConfig`: Specify the model class we are gonna try\n",
    "*   `ParellelConfig`: Experiments parameters, including the dir, other config's class, trials, hyperparameter search space and hardware related parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kq7ubuq2Fsmz"
   },
   "outputs": [],
   "source": [
    "from ablator import OptimizerConfig, TrainConfig\n",
    "from ablator.config.hpo import SearchSpace\n",
    "\n",
    "# Define the training configuration object\n",
    "train_config = TrainConfig(\n",
    "    dataset=\"mnist\",\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    scheduler_config=None,\n",
    "    optimizer_config=OptimizerConfig(\n",
    "        name=\"sgd\", arguments={\"lr\": 0.001, \"momentum\": 0.1}\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Define the model configuration object\n",
    "model_config = LenetConfig(name=\"lenet5\")\n",
    "\n",
    "# Define the Main parallel running configuration object\n",
    "run_config = MyParallelConfig(\n",
    "    train_config=train_config,\n",
    "    model_config=model_config,\n",
    "    metrics_n_batches=200,\n",
    "    total_trials=5,\n",
    "    concurrent_trials=5,\n",
    "    optim_metrics={\"val_loss\": \"min\"},\n",
    "    optim_metric_name=\"val_loss\",\n",
    "    gpu_mb_per_experiment=1024,\n",
    "    device=\"cuda\",\n",
    "    search_space={\n",
    "        \"train_config.optimizer_config.arguments.momentum\": SearchSpace(\n",
    "            value_range=(\"0.01\", \"0.1\"), value_type=\"float\"\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2guR18nMhy1"
   },
   "source": [
    "### Hyperparameter tuning\n",
    "\n",
    "In this demo, we will train the model with different `momentum` values for the `SGD` optimizer. To achieve this functionality, we specified these parameters in the configurations object above:\n",
    "\n",
    "- `search_space`: Specify the hyperparameters we want to try with different values. We can specify their names, value ranges and value types. Ablator will generate different values for each hyperparameter according to the metrics and algorithms\n",
    "- `total_trials`: Specify how many trials we will have for different hyperparameters values.\n",
    "- `device`: Specify the hardware we will use to run our experiments\n",
    "\n",
    "Please refer to Ablator documentations for more information on how set the configurations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6ztvvnI2WbW"
   },
   "source": [
    "## Setmup the model and datasets\n",
    "\n",
    "After we created our configurations, we can proceed and create our customized models and datasets.\n",
    "\n",
    "### Model implementations\n",
    "\n",
    "First, we define our customized model class. In this demo, we will use the LeNet-5 model defined by ourselves with each layer using PyTorch components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jYUj-kJZ2CDb"
   },
   "outputs": [],
   "source": [
    "# Customized Model class is defined here, where the model structure, forward pass\n",
    "# and loss function are defined\n",
    "\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.relu4(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, config: LenetConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.model = SimpleCNN()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        # self.optimizer = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    def forward(self, x, labels, custom_input=None):\n",
    "        # custom_input is for demo purposes only, defined in the dataset wrapper\n",
    "        out = self.model(x)\n",
    "        loss = self.loss(out, labels)\n",
    "        if labels is not None:\n",
    "            loss = self.loss(out, labels)\n",
    "\n",
    "        out = out.argmax(dim=-1)\n",
    "        return {\"y_pred\": out[:, None], \"y_true\": labels[:, None]}, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qnmgxa5zNSOU"
   },
   "source": [
    "### Datasets implementations\n",
    "\n",
    "Then, we will import the MNIST dataset and make dataloader out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Dac7fqrxNYC-"
   },
   "outputs": [],
   "source": [
    "# Create the training & validation dataloaders from the MNIST dataset.\n",
    "# Also, data preprocessing is defined here, including normalization and other transformations\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=\"./datasets\", train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./datasets\", train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=64, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ugidFvsINwTB"
   },
   "source": [
    "### Evaluation function implementations\n",
    "\n",
    "Also, we will define a evaluation function for training process and model evaluation. We will choose accuracy from the sklearn package as our metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "T_GKbKheOELL"
   },
   "outputs": [],
   "source": [
    "def my_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true.flatten(), y_pred.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H53BkivBOJir"
   },
   "source": [
    "### Final Wrap-up\n",
    "\n",
    "As a last step, we can wrap up the model, datasets and configurations into a wrapper class inheriting from ModelWrapper base class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zLLMX_CzPkry"
   },
   "outputs": [],
   "source": [
    "# Custom Model Wrapper, extending ModelWrapper class from Ablator\n",
    "class MyModelWrapper(ModelWrapper):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def make_dataloader_train(self, run_config: LenetRunConfig):  # type: ignore\n",
    "        return trainloader\n",
    "\n",
    "    def make_dataloader_val(self, run_config: LenetRunConfig):  # type: ignore\n",
    "        return testloader\n",
    "\n",
    "    def evaluation_functions(self) -> Dict[str, Callable]:\n",
    "        return {\"accuracy_score\": my_accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbuGPUMmRBvk"
   },
   "source": [
    "## Launch Ablator\n",
    "\n",
    "After we finished the configurations and customizations, we can launch our Ablator to run the experiments now.\n",
    "\n",
    "The launching process follows these steps:\n",
    "\n",
    "*   Create target directory for results\n",
    "*   Initiate ray enviroments\n",
    "*   Run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UsZIiElKbmoo",
    "outputId": "bd55efff-88ae-4643-c740-65c124450ba0"
   },
   "outputs": [],
   "source": [
    "# Create results directory\n",
    "!mkdir -p working_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NL5WEPEe0eWo",
    "outputId": "2f71361b-2e60-498b-a258-d8268cf64720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find any active Ray processes.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!ray stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYqeT9Xh084-",
    "outputId": "3761c8cb-f42a-4f90-8b39-a7b93ddf5355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-27 22:34:37: \u001b[93mMetrics batch-limit 200 is larger than 20% of the train dataloader length 938. You might experience slow-down during training. Consider decreasing `metrics_n_batches`.\u001b[0m\n",
      "2023-08-27 22:34:37: Creating new model\n",
      "2023-08-27 22:34:44: Evaluation Step [1] val_loss: 2.31e+00 val_accuracy_score: 0.161900 train_loss: 2.30e+00 best_iteration: 00000938 best_val_loss: 2.31e+00 current_epoch: 00000001 current_iteration: 00000938 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: nan\n",
      "2023-08-27 22:34:44: val_loss: 2.31e+00 val_accuracy_score: 0.161900 train_loss: 2.30e+00 best_iteration: 00000938 best_val_loss: 2.31e+00 current_epoch: 00000001 current_iteration: 00000938 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.185000\n",
      "2023-08-27 22:34:48: Evaluation Step [2] val_loss: 2.30e+00 val_accuracy_score: 0.236400 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.185000\n",
      "2023-08-27 22:34:48: val_loss: 2.30e+00 val_accuracy_score: 0.236400 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.275000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.2950439453125,\n",
       " 'val_accuracy_score': 0.2364,\n",
       " 'train_loss': 2.2866522515570367,\n",
       " 'best_iteration': 1876,\n",
       " 'best_val_loss': 2.2950439453125,\n",
       " 'current_epoch': 2,\n",
       " 'current_iteration': 1876,\n",
       " 'epochs': 10,\n",
       " 'learning_rate': 0.001,\n",
       " 'total_steps': 9380,\n",
       " 'train_accuracy_score': 0.275}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Debug to make sure your model can train just fine.\n",
    "\n",
    "import shutil\n",
    "\n",
    "EXPERIMENT_DIR = Path.cwd().joinpath(\"experiment_dir\")\n",
    "shutil.rmtree(EXPERIMENT_DIR, ignore_errors=True)\n",
    "run_config.experiment_dir = None\n",
    "\n",
    "wrapper = MyModelWrapper(\n",
    "    model_class=MyModel,\n",
    ")\n",
    "wrapper.train(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FSZo_C1bRG1l",
    "outputId": "995fb941-6a3e-4694-f542-d97cef7cb964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-27 22:35:00:  - \u001b[93mNo git repository was detected at /home/iordanis/ablator-tutorials/examples/working_dir. We recommend setting the working directory to a git repository to keep track of changes.\u001b[0m\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:00:  - \u001b[93mNo git repository was detected at /home/iordanis/ablator-tutorials/examples/working_dir. We recommend setting the working directory to a git repository to keep track of changes.\u001b[0m\n",
      "2023-08-27 22:35:00:  - Scheduling uid: 54a0_c111_2cd2\n",
      "Parameters: \n",
      "\ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.020468748655217375\n",
      "\texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/54a0_c111_2cd2\n",
      "-----\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:00:  - Scheduling uid: 54a0_c111_2cd2\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m Parameters: \n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.020468748655217375\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/54a0_c111_2cd2\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m -----\n",
      "2023-08-27 22:35:00:  - Scheduling uid: f8f0_c111_1e93\n",
      "Parameters: \n",
      "\ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.04524082708741928\n",
      "\texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/f8f0_c111_1e93\n",
      "-----\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:00:  - Scheduling uid: f8f0_c111_1e93\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m Parameters: \n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.04524082708741928\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/f8f0_c111_1e93\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m -----\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:02: Model directory: /home/iordanis/ablator-tutorials/examples/experiment_dir/54a0_c111_2cd2\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:02: \u001b[93mMetrics batch-limit 200 is larger than 20% of the train dataloader length 938. You might experience slow-down during training. Consider decreasing `metrics_n_batches`.\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:02: Creating new model\n",
      "2023-08-27 22:35:03:  - Scheduling uid: 0f10_c111_5990\n",
      "Parameters: \n",
      "\ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.01856869301787909\n",
      "\texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/0f10_c111_5990\n",
      "-----\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:03:  - Scheduling uid: 0f10_c111_5990\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m Parameters: \n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.01856869301787909\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/0f10_c111_5990\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m -----\n",
      "2023-08-27 22:35:03:  - Scheduling uid: 58b2_c111_3aac\n",
      "Parameters: \n",
      "\ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.048063915260371536\n",
      "\texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/58b2_c111_3aac\n",
      "-----\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:03:  - Scheduling uid: 58b2_c111_3aac\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m Parameters: \n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.048063915260371536\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/58b2_c111_3aac\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m -----\n",
      "2023-08-27 22:35:06:  - Scheduling uid: ca2b_c111_b417\n",
      "Parameters: \n",
      "\ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.08109756377087539\n",
      "\texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/ca2b_c111_b417\n",
      "-----\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:06:  - Scheduling uid: ca2b_c111_b417\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m Parameters: \n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \ttrain_config.optimizer_config.arguments.momentum:(float)0.1->(float)0.08109756377087539\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m \texperiment_dir:(str)/home/iordanis/ablator-tutorials/examples/experiment_dir->(str)/home/iordanis/ablator-tutorials/examples/experiment_dir/ca2b_c111_b417\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m -----\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:08: Evaluation Step [1] val_loss: 2.31e+00 val_accuracy_score: 0.123100 train_loss: 2.30e+00 best_iteration: 00000938 best_val_loss: 2.31e+00 current_epoch: 00000001 current_iteration: 00000938 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: nan\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:08: val_loss: 2.31e+00 val_accuracy_score: 0.123100 train_loss: 2.30e+00 best_iteration: 00000938 best_val_loss: 2.31e+00 current_epoch: 00000001 current_iteration: 00000938 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.130000\n",
      "\u001b[2m\u001b[36m(58b2_c111_3aac pid=2400486)\u001b[0m 2023-08-27 22:35:06: Model directory: /home/iordanis/ablator-tutorials/examples/experiment_dir/58b2_c111_3aac\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(58b2_c111_3aac pid=2400486)\u001b[0m 2023-08-27 22:35:06: \u001b[93mMetrics batch-limit 200 is larger than 20% of the train dataloader length 938. You might experience slow-down during training. Consider decreasing `metrics_n_batches`.\u001b[0m\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(58b2_c111_3aac pid=2400486)\u001b[0m 2023-08-27 22:35:06: Creating new model\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:13: Evaluation Step [2] val_loss: 2.30e+00 val_accuracy_score: 0.168000 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.130000\n",
      "\u001b[2m\u001b[36m(58b2_c111_3aac pid=2400486)\u001b[0m 2023-08-27 22:35:12: Evaluation Step [1] val_loss: 2.30e+00 val_accuracy_score: 0.101000 train_loss: 2.30e+00 best_iteration: 00000938 best_val_loss: 2.30e+00 current_epoch: 00000001 current_iteration: 00000938 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: nan\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:13: val_loss: 2.30e+00 val_accuracy_score: 0.168000 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.190000\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:35:13: val_loss: 2.30e+00 val_accuracy_score: 0.168000 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.190000\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:35:13: val_loss: 2.30e+00 val_accuracy_score: 0.168000 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.190000\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:35:13: val_loss: 2.30e+00 val_accuracy_score: 0.168000 train_loss: 2.29e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.190000\n",
      "\u001b[2m\u001b[36m(f8f0_c111_1e93 pid=2399702)\u001b[0m 2023-08-27 22:35:18: Evaluation Step [3] val_loss: 2.30e+00 val_accuracy_score: 0.210400 train_loss: 2.30e+00 best_iteration: 00002814 best_val_loss: 2.30e+00 current_epoch: 00000003 current_iteration: 00002814 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.170000\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:35:18: Evaluation Step [3] val_loss: 2.30e+00 val_accuracy_score: 0.210400 train_loss: 2.30e+00 best_iteration: 00002814 best_val_loss: 2.30e+00 current_epoch: 00000003 current_iteration: 00002814 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.170000\n",
      "\u001b[2m\u001b[36m(0f10_c111_5990 pid=2400482)\u001b[0m 2023-08-27 22:35:17: val_loss: 2.30e+00 val_accuracy_score: 0.112100 train_loss: 2.30e+00 best_iteration: 00001876 best_val_loss: 2.30e+00 current_epoch: 00000002 current_iteration: 00001876 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.060000\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(f8f0_c111_1e93 pid=2399702)\u001b[0m 2023-08-27 22:35:23: Evaluation Step [4] val_loss: 2.29e+00 val_accuracy_score: 0.236600 train_loss: 2.29e+00 best_iteration: 00003752 best_val_loss: 2.29e+00 current_epoch: 00000004 current_iteration: 00003752 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.210000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(f8f0_c111_1e93 pid=2399702)\u001b[0m 2023-08-27 22:35:23: val_loss: 2.29e+00 val_accuracy_score: 0.236600 train_loss: 2.29e+00 best_iteration: 00003752 best_val_loss: 2.29e+00 current_epoch: 00000004 current_iteration: 00003752 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.280000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:29: Evaluation Step [5] val_loss: 2.06e+00 val_accuracy_score: 0.548400 train_loss: 2.17e+00 best_iteration: 00004690 best_val_loss: 2.06e+00 current_epoch: 00000005 current_iteration: 00004690 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.360000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:29: val_loss: 2.06e+00 val_accuracy_score: 0.548400 train_loss: 2.17e+00 best_iteration: 00004690 best_val_loss: 2.06e+00 current_epoch: 00000005 current_iteration: 00004690 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.570000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:34: Evaluation Step [6] val_loss: 1.31e+00 val_accuracy_score: 0.663800 train_loss: 1.78e+00 best_iteration: 00005628 best_val_loss: 1.31e+00 current_epoch: 00000006 current_iteration: 00005628 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.570000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:34: val_loss: 1.31e+00 val_accuracy_score: 0.663800 train_loss: 1.78e+00 best_iteration: 00005628 best_val_loss: 1.31e+00 current_epoch: 00000006 current_iteration: 00005628 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.635000\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m ablator \u001b[39m=\u001b[39m ParallelTrainer(\n\u001b[1;32m     14\u001b[0m     wrapper\u001b[39m=\u001b[39mwrapper,\n\u001b[1;32m     15\u001b[0m     run_config\u001b[39m=\u001b[39mrun_config,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[39m# NOTE to run on a cluster you will need to start ray with `ray start --head` and pass ray_head_address=\"auto\"\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m ablator\u001b[39m.\u001b[39;49mlaunch(working_directory\u001b[39m=\u001b[39;49mWORKING_DIRECTORY)\n",
      "File \u001b[0;32m~/ablator-win/ablator/main/mp.py:463\u001b[0m, in \u001b[0;36mParallelTrainer.launch\u001b[0;34m(self, working_directory, auxilary_modules, ray_head_address, resume, excluding_files)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnhandled Exception: \u001b[39m\u001b[39m{\u001b[39;00mexception\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    462\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_heartbeat()\n\u001b[1;32m    464\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_summary()\n",
      "File \u001b[0;32m~/ablator-win/ablator/main/mp.py:198\u001b[0m, in \u001b[0;36mParallelTrainer._heartbeat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_display\u001b[39m.\u001b[39mrefresh(force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    195\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_update_resources \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39mor\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_update_resources \u001b[39m>\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m    197\u001b[0m ):\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavailable_resources \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_manager\u001b[39m.\u001b[39;49mavailable_resources()\n",
      "File \u001b[0;32m~/ablator-win/ablator/mp/node_manager.py:115\u001b[0m, in \u001b[0;36mNodeManager.available_resources\u001b[0;34m(self, node_ips, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mavailable_resources\u001b[39m(\n\u001b[1;32m    113\u001b[0m     \u001b[39mself\u001b[39m, node_ips: \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, timeout: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m DEFAULT_TIMEOUT\n\u001b[1;32m    114\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Resource]:\n\u001b[0;32m--> 115\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mutilization(node_ips, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    116\u001b[0m     node_id_map: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m {\n\u001b[1;32m    117\u001b[0m         n\u001b[39m.\u001b[39mnode_id: n\u001b[39m.\u001b[39mnode_ip\n\u001b[1;32m    118\u001b[0m         \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m list_nodes(address\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mray_address, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    119\u001b[0m     }\n\u001b[1;32m    120\u001b[0m     node_ip_tasks: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m defaultdict(\u001b[39mlambda\u001b[39;00m: [])\n",
      "File \u001b[0;32m~/ablator-win/ablator/mp/node_manager.py:110\u001b[0m, in \u001b[0;36mNodeManager.utilization\u001b[0;34m(self, node_ips, timeout)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mutilization\u001b[39m(\n\u001b[1;32m    108\u001b[0m     \u001b[39mself\u001b[39m, node_ips: \u001b[39mlist\u001b[39m \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, timeout: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m DEFAULT_TIMEOUT\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, Resource]:\n\u001b[0;32m--> 110\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_lambda(utilization, node_ips, timeout\u001b[39m=\u001b[39;49mtimeout)\n",
      "File \u001b[0;32m~/ablator-win/ablator/mp/node_manager.py:165\u001b[0m, in \u001b[0;36mNodeManager.run_lambda\u001b[0;34m(self, fn, node_ips, timeout)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mfor\u001b[39;00m node_ip \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_node_ips(node_ips):\n\u001b[1;32m    164\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m         results[node_ip] \u001b[39m=\u001b[39m ray\u001b[39m.\u001b[39;49mget(\n\u001b[1;32m    166\u001b[0m             ray\u001b[39m.\u001b[39;49mremote(num_cpus\u001b[39m=\u001b[39;49m\u001b[39m0.001\u001b[39;49m)(fn)\n\u001b[1;32m    167\u001b[0m             \u001b[39m.\u001b[39;49moptions(resources\u001b[39m=\u001b[39;49m{\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnode:\u001b[39;49m\u001b[39m{\u001b[39;49;00mnode_ip\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m: \u001b[39m0.001\u001b[39;49m})\n\u001b[1;32m    168\u001b[0m             \u001b[39m.\u001b[39;49mremote(),\n\u001b[1;32m    169\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    170\u001b[0m         )\n\u001b[1;32m    171\u001b[0m     \u001b[39m# pylint: disable=broad-exception-caught\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/ray/_private/auto_init_hook.py:18\u001b[0m, in \u001b[0;36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[1;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mauto_init_wrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     17\u001b[0m     auto_init_ray()\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/ray/_private/client_mode_hook.py:103\u001b[0m, in \u001b[0;36mclient_mode_hook.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[39mif\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(ray, func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/ray/_private/worker.py:2534\u001b[0m, in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2530\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject_refs\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must either be an ObjectRef or a list of ObjectRefs.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2531\u001b[0m     )\n\u001b[1;32m   2533\u001b[0m \u001b[39m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[0;32m-> 2534\u001b[0m values, debugger_breakpoint \u001b[39m=\u001b[39m worker\u001b[39m.\u001b[39;49mget_objects(object_refs, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   2535\u001b[0m \u001b[39mfor\u001b[39;00m i, value \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(values):\n\u001b[1;32m   2536\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, RayError):\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/ray/_private/worker.py:759\u001b[0m, in \u001b[0;36mWorker.get_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    754\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAttempting to call `get` on the value \u001b[39m\u001b[39m{\u001b[39;00mobject_ref\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mwhich is not an ray.ObjectRef.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    756\u001b[0m         )\n\u001b[1;32m    758\u001b[0m timeout_ms \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(timeout \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m) \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m--> 759\u001b[0m data_metadata_pairs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcore_worker\u001b[39m.\u001b[39;49mget_objects(\n\u001b[1;32m    760\u001b[0m     object_refs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_task_id, timeout_ms\n\u001b[1;32m    761\u001b[0m )\n\u001b[1;32m    762\u001b[0m debugger_breakpoint \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m \u001b[39mfor\u001b[39;00m data, metadata \u001b[39min\u001b[39;00m data_metadata_pairs:\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:2554\u001b[0m, in \u001b[0;36mray._raylet.CoreWorker.get_objects\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpython/ray/_raylet.pyx:444\u001b[0m, in \u001b[0;36mray._raylet.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:39: Evaluation Step [7] val_loss: 7.91e-01 val_accuracy_score: 0.780900 train_loss: 1.03e+00 best_iteration: 00006566 best_val_loss: 7.91e-01 current_epoch: 00000007 current_iteration: 00006566 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.635000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:39: val_loss: 7.91e-01 val_accuracy_score: 0.780900 train_loss: 1.03e+00 best_iteration: 00006566 best_val_loss: 7.91e-01 current_epoch: 00000007 current_iteration: 00006566 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.730000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(f8f0_c111_1e93 pid=2399702)\u001b[0m 2023-08-27 22:35:45: Evaluation Step [8] val_loss: 2.22e+00 val_accuracy_score: 0.510300 train_loss: 2.24e+00 best_iteration: 00007504 best_val_loss: 2.22e+00 current_epoch: 00000008 current_iteration: 00007504 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.410000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(0f10_c111_5990 pid=2400482)\u001b[0m 2023-08-27 22:35:43: val_loss: 2.00e+00 val_accuracy_score: 0.354600 train_loss: 2.12e+00 best_iteration: 00006566 best_val_loss: 2.00e+00 current_epoch: 00000007 current_iteration: 00006566 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.375000\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:50: Evaluation Step [9] val_loss: 5.09e-01 val_accuracy_score: 0.842400 train_loss: 5.86e-01 best_iteration: 00008442 best_val_loss: 5.09e-01 current_epoch: 00000009 current_iteration: 00008442 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.800000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:50: val_loss: 5.09e-01 val_accuracy_score: 0.842400 train_loss: 5.86e-01 best_iteration: 00008442 best_val_loss: 5.09e-01 current_epoch: 00000009 current_iteration: 00008442 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.870000\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:55: Evaluation Step [10] val_loss: 4.10e-01 val_accuracy_score: 0.860200 train_loss: 5.13e-01 best_iteration: 00009380 best_val_loss: 4.10e-01 current_epoch: 00000010 current_iteration: 00009380 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.870000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(54a0_c111_2cd2 pid=2399690)\u001b[0m 2023-08-27 22:35:55: val_loss: 4.10e-01 val_accuracy_score: 0.860200 train_loss: 5.13e-01 best_iteration: 00009380 best_val_loss: 4.10e-01 current_epoch: 00000010 current_iteration: 00009380 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.870000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(FileLogger pid=2398935)\u001b[0m 2023-08-27 22:35:55:  - Finished training - 54a0_c111\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:36:03: Evaluation Step [10] val_loss: 1.96e-01 val_accuracy_score: 0.891700 train_loss: 4.05e-01 best_iteration: 00009380 best_val_loss: 1.96e-01 current_epoch: 00000010 current_iteration: 00009380 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.905000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(ca2b_c111_b417 pid=2401286)\u001b[0m 2023-08-27 22:36:03: val_loss: 1.96e-01 val_accuracy_score: 0.891700 train_loss: 4.05e-01 best_iteration: 00009380 best_val_loss: 1.96e-01 current_epoch: 00000010 current_iteration: 00009380 epochs: 00000010 learning_rate: 0.001000 total_steps: 00009380 train_accuracy_score: 0.885000\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(0f10_c111_5990 pid=2400482)\u001b[0m 2023-08-27 22:35:59:  - Finished training - 0f10_c111\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Launch Ablator to run experiments\n",
    "\n",
    "\n",
    "WORKING_DIRECTORY = Path.cwd().joinpath(\"working_dir\")\n",
    "# mp_train prepares and launches parallel training\n",
    "\n",
    "wrapper = MyModelWrapper(\n",
    "    model_class=MyModel,\n",
    ")\n",
    "shutil.rmtree(EXPERIMENT_DIR, ignore_errors=True)\n",
    "run_config.experiment_dir = EXPERIMENT_DIR\n",
    "\n",
    "ablator = ParallelTrainer(\n",
    "    wrapper=wrapper,\n",
    "    run_config=run_config,\n",
    ")\n",
    "\n",
    "# NOTE to run on a cluster you will need to start ray with `ray start --head` and pass ray_head_address=\"auto\"\n",
    "ablator.launch(working_directory=WORKING_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3apIT0I4YJ7"
   },
   "source": [
    "## Experiments results analysis\n",
    "\n",
    "After running the experiments, the results are cached in the directory: `/tmp/dir`, as specified in the configurations. The results directory follows these structures:\n",
    "\n",
    "```\n",
    "- dir\n",
    "    - experiment_<experiment_id>\n",
    "        - <trial1_id>\n",
    "          - best_checkpoints/\n",
    "          - checkpoints/\n",
    "          - dashboard/\n",
    "          - config.yaml\n",
    "          - metadata.json\n",
    "          - results.json\n",
    "          - train.log\n",
    "        - <trial2_id>\n",
    "        - <trial3_id>\n",
    "        - ...\n",
    "        - <experiment_id>_optuna.db\n",
    "        - <experiment_id>_state.db\n",
    "        - default_config.yaml\n",
    "        - mp.log\n",
    "```\n",
    "\n",
    "To utilize the results, here are some detailed explations to introduce these files directories:\n",
    "\n",
    "- `default_config.yaml`: the overrall configurations for model, training and hyperparameters tuning\n",
    "- `train.log`: console infomation during the training process\n",
    "- `results.json`: metrics of the model during & after the training process\n",
    "- `config.yaml`: specific configurations for each trial, including the trail hyperparameters\n",
    "- `checkpoints/`: directory to cache the training checkpoints and trained models\n",
    "- `dashboard/`: directory to cache the metrics data for Tensorboard visualization\n",
    "\n",
    "In the folling section, we will use Tensorboard to visualize the results from different trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6DaDY6NJ8c9"
   },
   "source": [
    "### Tensorboard visualization\n",
    "\n",
    "To utilize the Tensorboard, we load Tensorboard extension and then input each data directory into the Tensorboard and launch it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCFbonfc4Ry6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the TensorBoard extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3R3xHimZ5A-R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2424198), started 0:00:09 ago. (Use '!kill 2424198' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-88a072872eb53617\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-88a072872eb53617\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "\n",
    "# Load TensorBoard with multiple directories\n",
    "notebook.start(f\"--logdir {EXPERIMENT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N446HCexKxp7"
   },
   "source": [
    "### Results analysis\n",
    "\n",
    "Tensorboard gives us a clear visual on the performance of our model under different hyperparameter, to be specific, the momentum values of SGD optimizer.\n",
    "\n",
    "When the momentum is set to be `0.027` and `0.044`, the model can have a overrall best performance, both on the training set and on the validations set. Higher or lower momentum values may both lead to a poorer performance to our LeNet-5 model on the MNIST dataset."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
